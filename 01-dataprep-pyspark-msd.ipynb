{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11782323,"sourceType":"datasetVersion","datasetId":7392615}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Notebook Initialization â€“ Objective & Imports\n\n# Objective\n# - Process the 10,000-song subset using PySpark.\n# - Aggregate time-series features (mean, max, min, std).\n# - Store the processed data in Parquet format.\n# - (Optional) Push data to MongoDB Atlas.\n\n# Import Libraries\nimport os\nimport glob\nimport h5py\nimport pandas as pd\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, mean, stddev, min, max\nfrom pymongo import MongoClient\n\nprint(\"Libraries imported successfully\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:37.852796Z","iopub.execute_input":"2025-05-12T11:43:37.853119Z","iopub.status.idle":"2025-05-12T11:43:39.443910Z","shell.execute_reply.started":"2025-05-12T11:43:37.853094Z","shell.execute_reply":"2025-05-12T11:43:39.443026Z"}},"outputs":[{"name":"stdout","text":"Libraries imported successfully\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from pyspark import SparkConf\n\n# Stop existing Spark session if running\ntry:\n    spark.stop()\nexcept:\n    pass\n\n# Reconfigure Spark for CPU usage\nconf = SparkConf()\nconf.set(\"spark.executor.memory\", \"24g\")  # Maximize memory usage for large data\nconf.set(\"spark.driver.memory\", \"24g\")\nconf.set(\"spark.executor.cores\", \"4\")  # Utilize all 6 CPU cores\nconf.set(\"spark.task.cpus\", \"1\")       # 1 CPU core per task\n\n# Reinitialize Spark session\nspark = SparkSession.builder.config(conf=conf).appName(\"MSD_DataPrep_CPU\").getOrCreate()\n\nprint(\"Spark session reconfigured for CPU processing.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:39.445160Z","iopub.execute_input":"2025-05-12T11:43:39.445906Z","iopub.status.idle":"2025-05-12T11:43:46.535675Z","shell.execute_reply.started":"2025-05-12T11:43:39.445884Z","shell.execute_reply":"2025-05-12T11:43:46.534542Z"}},"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/05/12 11:43:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"},{"name":"stdout","text":"Spark session reconfigured for CPU processing.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"### Path Definitions\n\nINPUT_PATH = \"/kaggle/input/millionsongsubset/MillionSongSubset/*/*/*/*.h5\"\n\n# MongoDB Connection String (Optional)\nMONGO_URI = \"mongodb+srv://admin:yourpassword123@bigdatahw.udemiib.mongodb.net/?retryWrites=true&w=majority&appName=BigDataHW\"\n\nprint(\"Paths defined successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:46.537655Z","iopub.execute_input":"2025-05-12T11:43:46.537932Z","iopub.status.idle":"2025-05-12T11:43:46.543796Z","shell.execute_reply.started":"2025-05-12T11:43:46.537908Z","shell.execute_reply":"2025-05-12T11:43:46.542929Z"}},"outputs":[{"name":"stdout","text":"Paths defined successfully\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"### MongoDB Connection (Optional)\n\n# Test MongoDB Connection\ntry:\n    client = MongoClient(MONGO_URI)\n    db = client[\"msd_database\"]\n    collection = db[\"test_collection\"]\n\n    # Insert sample document\n    sample_doc = {\"status\": \"Connection successful\"}\n    collection.insert_one(sample_doc)\n\n    print(\"MongoDB connection and sample insertion successful\")\n\nexcept Exception as e:\n    print(f\"MongoDB connection failed: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:46.544729Z","iopub.execute_input":"2025-05-12T11:43:46.545087Z","iopub.status.idle":"2025-05-12T11:43:47.986306Z","shell.execute_reply.started":"2025-05-12T11:43:46.545047Z","shell.execute_reply":"2025-05-12T11:43:47.985341Z"}},"outputs":[{"name":"stdout","text":"MongoDB connection and sample insertion successful\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"### Data Loading and Exploration - Inspecting HDF5 Structure\n\n# Select a sample file to inspect\nsample_file = glob.glob(INPUT_PATH)[0]\n\n# Open the file and display its structure\nwith h5py.File(sample_file, 'r') as hdf:\n    def print_structure(name, obj):\n        print(f\"{name}: {type(obj)}\")\n    \n    hdf.visititems(print_structure)\n\nprint(\"Sample HDF5 file structure displayed successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:48.562623Z","iopub.execute_input":"2025-05-12T11:43:48.562961Z","iopub.status.idle":"2025-05-12T11:43:54.526822Z","shell.execute_reply.started":"2025-05-12T11:43:48.562936Z","shell.execute_reply":"2025-05-12T11:43:54.525824Z"}},"outputs":[{"name":"stdout","text":"analysis: <class 'h5py._hl.group.Group'>\nanalysis/bars_confidence: <class 'h5py._hl.dataset.Dataset'>\nanalysis/bars_start: <class 'h5py._hl.dataset.Dataset'>\nanalysis/beats_confidence: <class 'h5py._hl.dataset.Dataset'>\nanalysis/beats_start: <class 'h5py._hl.dataset.Dataset'>\nanalysis/sections_confidence: <class 'h5py._hl.dataset.Dataset'>\nanalysis/sections_start: <class 'h5py._hl.dataset.Dataset'>\nanalysis/segments_confidence: <class 'h5py._hl.dataset.Dataset'>\nanalysis/segments_loudness_max: <class 'h5py._hl.dataset.Dataset'>\nanalysis/segments_loudness_max_time: <class 'h5py._hl.dataset.Dataset'>\nanalysis/segments_loudness_start: <class 'h5py._hl.dataset.Dataset'>\nanalysis/segments_pitches: <class 'h5py._hl.dataset.Dataset'>\nanalysis/segments_start: <class 'h5py._hl.dataset.Dataset'>\nanalysis/segments_timbre: <class 'h5py._hl.dataset.Dataset'>\nanalysis/songs: <class 'h5py._hl.dataset.Dataset'>\nanalysis/tatums_confidence: <class 'h5py._hl.dataset.Dataset'>\nanalysis/tatums_start: <class 'h5py._hl.dataset.Dataset'>\nmetadata: <class 'h5py._hl.group.Group'>\nmetadata/artist_terms: <class 'h5py._hl.dataset.Dataset'>\nmetadata/artist_terms_freq: <class 'h5py._hl.dataset.Dataset'>\nmetadata/artist_terms_weight: <class 'h5py._hl.dataset.Dataset'>\nmetadata/similar_artists: <class 'h5py._hl.dataset.Dataset'>\nmetadata/songs: <class 'h5py._hl.dataset.Dataset'>\nmusicbrainz: <class 'h5py._hl.group.Group'>\nmusicbrainz/artist_mbtags: <class 'h5py._hl.dataset.Dataset'>\nmusicbrainz/artist_mbtags_count: <class 'h5py._hl.dataset.Dataset'>\nmusicbrainz/songs: <class 'h5py._hl.dataset.Dataset'>\nSample HDF5 file structure displayed successfully\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from pyspark.sql import Row\nimport numpy as np\n\nimport unicodedata\nimport re\n\ndef sanitize_artist_name(artist_name):\n    \"\"\"\n    Sanitize artist name:\n    - Apply Unicode normalization (NFKD) to remove accents.\n    - Convert to lowercase.\n    - Remove special characters.\n    - Truncate to 30 characters.\n    \"\"\"\n    # Normalize to remove accents\n    sanitized_name = unicodedata.normalize('NFKD', artist_name).encode('ASCII', 'ignore').decode('utf-8')\n    \n    # Convert to lowercase\n    sanitized_name = sanitized_name.lower()\n    \n    # Remove special characters and limit length to 30 characters\n    sanitized_name = re.sub(r'[^\\w\\s]', '', sanitized_name).strip()[:30]\n    \n    # Replace spaces with underscores\n    sanitized_name = sanitized_name.replace(\" \", \"_\")\n\n    # Handle empty or missing artist names\n    if not sanitized_name:\n        sanitized_name = \"unknown_artist\"\n\n    return sanitized_name\n\n# Enhanced Extraction Function with Sanitization\ndef extract_data_with_normalization(file_path):\n    try:\n        with h5py.File(file_path, 'r') as hdf:\n            # Extract metadata\n            try:\n                song_id = hdf['metadata/songs']['song_id'][0].decode('utf-8')\n            except:\n                return None\n\n            try:\n                artist_name = hdf['metadata/songs']['artist_name'][0].decode('utf-8')\n                artist_name = sanitize_artist_name(artist_name)\n            except:\n                artist_name = \"unknown_artist\"\n\n            try:\n                title = hdf['metadata/songs']['title'][0].decode('utf-8')\n            except:\n                title = \"unknown_title\"\n\n            # Extract and aggregate time-series data\n            try:\n                timbre = hdf['analysis/segments_timbre'][:]\n                pitch = hdf['analysis/segments_pitches'][:]\n\n                # Skip if data is missing\n                if timbre.size == 0 or pitch.size == 0:\n                    return None\n\n                # Compute statistics\n                t_mean = np.mean(timbre, axis=0).tolist()\n                t_max = np.max(timbre, axis=0).tolist()\n                t_min = np.min(timbre, axis=0).tolist()\n                t_std = np.std(timbre, axis=0).tolist()\n\n                p_mean = np.mean(pitch, axis=0).tolist()\n                p_max = np.max(pitch, axis=0).tolist()\n                p_min = np.min(pitch, axis=0).tolist()\n                p_std = np.std(pitch, axis=0).tolist()\n\n                return Row(\n                    song_id=song_id,\n                    artist_name=artist_name,\n                    title=title,\n                    timbre_mean=t_mean,\n                    timbre_max=t_max,\n                    timbre_min=t_min,\n                    timbre_std=t_std,\n                    pitch_mean=p_mean,\n                    pitch_max=p_max,\n                    pitch_min=p_min,\n                    pitch_std=p_std\n                )\n\n            except Exception as e:\n                print(f\"Data extraction error: {e}\")\n                return None\n\n    except Exception as e:\n        print(f\"File processing error: {e}\")\n        return None\n\n\nprint(\"Extraction function updated to include artist name sanitization.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:54.528382Z","iopub.execute_input":"2025-05-12T11:43:54.528737Z","iopub.status.idle":"2025-05-12T11:43:54.540959Z","shell.execute_reply.started":"2025-05-12T11:43:54.528704Z","shell.execute_reply":"2025-05-12T11:43:54.540039Z"}},"outputs":[{"name":"stdout","text":"Extraction function updated to include artist name sanitization.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType, IntegerType\n\n# Define Schema Without 'year'\nschema_by_artist = StructType([\n    StructField(\"song_id\", StringType(), True),\n    StructField(\"artist_name\", StringType(), True),\n    StructField(\"title\", StringType(), True),\n    StructField(\"timbre_mean\", ArrayType(FloatType()), True),\n    StructField(\"timbre_max\", ArrayType(FloatType()), True),\n    StructField(\"timbre_min\", ArrayType(FloatType()), True),\n    StructField(\"timbre_std\", ArrayType(FloatType()), True),\n    StructField(\"pitch_mean\", ArrayType(FloatType()), True),\n    StructField(\"pitch_max\", ArrayType(FloatType()), True),\n    StructField(\"pitch_min\", ArrayType(FloatType()), True),\n    StructField(\"pitch_std\", ArrayType(FloatType()), True)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:56.224182Z","iopub.execute_input":"2025-05-12T11:43:56.224512Z","iopub.status.idle":"2025-05-12T11:43:56.230614Z","shell.execute_reply.started":"2025-05-12T11:43:56.224456Z","shell.execute_reply":"2025-05-12T11:43:56.229704Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Recreate DataFrame using the updated extraction function\nfiles = glob.glob(INPUT_PATH, recursive=True)\n\ndata_rdd = spark.sparkContext.parallelize(files, numSlices=6) \\\n             .map(extract_data_with_normalization) \\\n             .filter(lambda x: x is not None)\n\n# Create DataFrame\nspark_df = spark.createDataFrame(data_rdd, schema_by_artist)\n\n# Verify schema and preview data\nspark_df.printSchema()\nspark_df.show(5, truncate=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:43:58.488423Z","iopub.execute_input":"2025-05-12T11:43:58.488795Z","iopub.status.idle":"2025-05-12T11:44:10.588093Z","shell.execute_reply.started":"2025-05-12T11:43:58.488766Z","shell.execute_reply":"2025-05-12T11:44:10.587312Z"}},"outputs":[{"name":"stdout","text":"root\n |-- song_id: string (nullable = true)\n |-- artist_name: string (nullable = true)\n |-- title: string (nullable = true)\n |-- timbre_mean: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- timbre_max: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- timbre_min: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- timbre_std: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- pitch_mean: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- pitch_max: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- pitch_min: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- pitch_std: array (nullable = true)\n |    |-- element: float (containsNull = true)\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"+------------------+--------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\n|song_id           |artist_name   |title              |timbre_mean                                                                                                                                |timbre_max                                                                                            |timbre_min                                                                                                      |timbre_std                                                                                                                         |pitch_mean                                                                                                                                    |pitch_max                                                     |pitch_min                                                                           |pitch_std                                                                                                                                     |\n+------------------+--------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\n|SOTEDAD12A8AE4735F|orbital       |Forever            |[39.32157, 6.516844, 23.708578, 10.636436, 1.148572, -17.32453, 12.015962, 6.970745, 2.7694502, 6.7983475, 5.452519, 11.377993]            |[48.838, 191.813, 189.508, 142.044, 105.988, 105.672, 112.282, 134.855, 131.468, 93.37, 73.64, 92.865]|[0.0, -248.26, -173.738, -86.369, -87.855, -101.944, -103.112, -74.671, -72.988, -57.473, -59.106, -76.753]     |[5.5113497, 69.0174, 55.502148, 32.18201, 25.470156, 26.33698, 29.416636, 19.29666, 22.770086, 19.401932, 14.850522, 25.389172]    |[0.41009885, 0.3645566, 0.4681166, 0.24636468, 0.351464, 0.34664443, 0.3190288, 0.4943671, 0.3735043, 0.6199981, 0.27316123, 0.20010029]      |[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  |[0.002, 0.004, 0.003, 0.003, 0.007, 0.004, 0.01, 0.01, 0.01, 0.024, 0.01, 0.001]    |[0.29420403, 0.3058539, 0.33243927, 0.23694986, 0.2863948, 0.28194582, 0.27449688, 0.33208942, 0.33098483, 0.34342957, 0.26544106, 0.23637629]|\n|SOUWZWV12AB0181ACF|kris_gruen    |Prayer Walk        |[43.890278, -89.25192, -22.637129, -22.975597, -23.777142, -14.043555, -14.108288, -12.219806, 7.1182775, -5.667286, 4.060265, 14.968142]  |[50.505, 171.13, 139.677, 334.288, 73.984, 117.895, 42.617, 151.994, 59.642, 83.307, 59.865, 72.0]    |[0.0, -248.416, -136.031, -137.85, -111.686, -209.599, -90.968, -81.224, -49.713, -91.435, -95.432, -92.687]    |[4.5190134, 49.744537, 33.571102, 33.39628, 30.702156, 23.616903, 23.876318, 22.826027, 17.3169, 17.42368, 14.414447, 18.152456]   |[0.373286, 0.11693737, 0.3490146, 0.3452881, 0.14585803, 0.256405, 0.12139666, 0.35558665, 0.10504593, 0.2702693, 0.29261377, 0.2315073]      |[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.976, 1.0, 1.0, 1.0]|[0.003, 0.006, 0.005, 0.003, 0.007, 0.005, 0.004, 0.007, 0.006, 0.007, 0.014, 0.006]|[0.32932666, 0.16484505, 0.3315956, 0.38314202, 0.1947592, 0.31272036, 0.13240612, 0.34252578, 0.113607764, 0.30697826, 0.31613627, 0.3132086]|\n|SOFAJOM12A8C141EE4|4_skins       |New War            |[46.810226, 41.306023, 40.84329, -3.4699106, 1.4934152, -15.112153, -7.938532, -0.6474308, 0.13559249, -6.3443274, 0.19135575, -5.984313]  |[52.869, 171.13, 127.591, 45.838, 70.959, 129.379, 27.987, 67.904, 38.288, 75.735, 56.385, 56.79]     |[0.0, -131.08, -65.464, -65.676, -93.561, -63.982, -58.102, -70.272, -37.499, -72.956, -26.657, -35.918]        |[5.7126975, 39.414158, 35.399014, 17.441784, 21.887815, 15.147407, 12.880156, 13.300988, 12.096301, 12.087529, 8.880887, 11.631738]|[0.49168435, 0.4256753, 0.57448125, 0.46158475, 0.5579133, 0.44376713, 0.4069586, 0.37351745, 0.323696, 0.3698331, 0.31854594, 0.48803493]    |[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  |[0.009, 0.016, 0.026, 0.027, 0.022, 0.009, 0.014, 0.017, 0.01, 0.012, 0.008, 0.008] |[0.3070258, 0.21079274, 0.30251172, 0.23553446, 0.31178215, 0.3031297, 0.22734675, 0.25663072, 0.19446658, 0.22494668, 0.21686706, 0.2917941] |\n|SOCCBOH12A8C13E947|rockit        |Some Kind of Record|[46.884056, 31.062284, 12.591344, 4.440421, -24.193872, -17.151476, 1.594063, -0.14998066, 4.386417, 3.472877, 0.4062523, -9.535078]       |[54.18, 129.396, 105.949, 403.623, 58.634, 121.904, 79.383, 82.986, 59.184, 90.421, 74.954, 40.155]   |[25.819, -100.153, -126.561, -105.848, -135.016, -220.891, -66.559, -67.587, -75.609, -74.369, -46.294, -55.048]|[5.046649, 45.231953, 30.739801, 34.359295, 31.300114, 29.519684, 20.41854, 17.578943, 17.08293, 13.755871, 14.2369795, 13.266249] |[0.38033366, 0.4429583, 0.3209461, 0.32677314, 0.5802635, 0.34298676, 0.34600103, 0.44966125, 0.30845678, 0.37428585, 0.2808647, 0.43238047]  |[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  |[0.014, 0.022, 0.016, 0.016, 0.021, 0.022, 0.025, 0.034, 0.03, 0.015, 0.015, 0.017] |[0.2728266, 0.32914257, 0.26057515, 0.21983574, 0.35199875, 0.24459752, 0.22776267, 0.3060521, 0.20539764, 0.31893018, 0.21329057, 0.31681713]|\n|SOBBWJS12AB0182522|betika__daouda|C'est pas ma faute |[44.009483, -0.6849293, -35.77042, -14.735756, 6.2774663, -14.848255, -26.523798, -4.3030953, -16.662634, -0.21954964, 4.328041, 6.9993715]|[52.167, 171.13, 72.251, 358.989, 117.217, 123.232, 62.874, 117.259, 54.2, 65.083, 70.645, 83.057]    |[0.0, -176.914, -147.173, -149.252, -86.484, -92.062, -111.382, -86.539, -79.771, -67.689, -63.071, -58.653]    |[4.067944, 40.635242, 32.472378, 40.18538, 31.284431, 29.280909, 25.025349, 23.982462, 19.55139, 15.617327, 18.976736, 18.859598]  |[0.44603336, 0.28118825, 0.32967433, 0.23954408, 0.20299524, 0.44371328, 0.20252979, 0.39092216, 0.2084456, 0.35885623, 0.3881549, 0.21603574]|[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  |[0.005, 0.005, 0.003, 0.003, 0.003, 0.004, 0.004, 0.002, 0.004, 0.005, 0.005, 0.006]|[0.32965237, 0.23357983, 0.28927004, 0.27708104, 0.19480968, 0.36366886, 0.17878048, 0.35195893, 0.19952497, 0.3063006, 0.33185014, 0.2212424]|\n+------------------+--------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import shutil\nimport os\n\n# Define the output path for partitioned Parquet data\nPARTITIONED_OUTPUT_PATH = \"/kaggle/working/msd_agg_parquet_by_artist\"\n\n# Remove the directory if it already exists\nif os.path.exists(PARTITIONED_OUTPUT_PATH):\n    shutil.rmtree(PARTITIONED_OUTPUT_PATH)\n\n# Export the DataFrame partitioned by 'artist_name'\nspark_df.write.mode(\"overwrite\").partitionBy(\"artist_name\").parquet(PARTITIONED_OUTPUT_PATH)\n\nprint(f\"Data successfully exported to {PARTITIONED_OUTPUT_PATH}, partitioned by sanitized 'artist_name'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:44:10.589246Z","iopub.execute_input":"2025-05-12T11:44:10.589555Z","iopub.status.idle":"2025-05-12T11:46:14.588027Z","shell.execute_reply.started":"2025-05-12T11:44:10.589528Z","shell.execute_reply":"2025-05-12T11:46:14.587066Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Data successfully exported to /kaggle/working/msd_agg_parquet_by_artist, partitioned by sanitized 'artist_name'.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Define CSV output path\nCSV_OUTPUT_PATH = \"/kaggle/working/msd_sample.csv\"\n\n# Extract a sample of 1000 rows\nsample_df = spark_df.limit(1000)\n\n# Export the sample to CSV\nsample_df.toPandas().to_csv(CSV_OUTPUT_PATH, index=False)\n\nprint(f\"Sample data exported to {CSV_OUTPUT_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:46:17.630614Z","iopub.execute_input":"2025-05-12T11:46:17.631428Z","iopub.status.idle":"2025-05-12T11:46:40.319590Z","shell.execute_reply.started":"2025-05-12T11:46:17.631397Z","shell.execute_reply":"2025-05-12T11:46:40.318801Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sample data exported to /kaggle/working/msd_sample.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Read and display the first few rows\nsample_data = pd.read_csv(CSV_OUTPUT_PATH)\nprint(sample_data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:47:11.798561Z","iopub.execute_input":"2025-05-12T11:47:11.798855Z","iopub.status.idle":"2025-05-12T11:47:11.850840Z","shell.execute_reply.started":"2025-05-12T11:47:11.798836Z","shell.execute_reply":"2025-05-12T11:47:11.849761Z"}},"outputs":[{"name":"stdout","text":"              song_id     artist_name                title  \\\n0  SOTEDAD12A8AE4735F         orbital              Forever   \n1  SOUWZWV12AB0181ACF      kris_gruen          Prayer Walk   \n2  SOFAJOM12A8C141EE4         4_skins              New War   \n3  SOCCBOH12A8C13E947          rockit  Some Kind of Record   \n4  SOBBWJS12AB0182522  betika__daouda   C'est pas ma faute   \n\n                                         timbre_mean  \\\n0  [39.321571350097656, 6.516843795776367, 23.708...   \n1  [43.89027786254883, -89.25192260742188, -22.63...   \n2  [46.81022644042969, 41.30602264404297, 40.8432...   \n3  [46.884056091308594, 31.062284469604492, 12.59...   \n4  [44.009483337402344, -0.6849293112754822, -35....   \n\n                                          timbre_max  \\\n0  [48.8380012512207, 191.81300354003906, 189.507...   \n1  [50.505001068115234, 171.1300048828125, 139.67...   \n2  [52.86899948120117, 171.1300048828125, 127.591...   \n3  [54.18000030517578, 129.39599609375, 105.94899...   \n4  [52.16699981689453, 171.1300048828125, 72.2509...   \n\n                                          timbre_min  \\\n0  [0.0, -248.25999450683594, -173.73800659179688...   \n1  [0.0, -248.41600036621094, -136.031005859375, ...   \n2  [0.0, -131.0800018310547, -65.46399688720703, ...   \n3  [25.819000244140625, -100.15299987792969, -126...   \n4  [0.0, -176.91400146484375, -147.17300415039062...   \n\n                                          timbre_std  \\\n0  [5.511349678039551, 69.01740264892578, 55.5021...   \n1  [4.519013404846191, 49.744537353515625, 33.571...   \n2  [5.712697505950928, 39.41415786743164, 35.3990...   \n3  [5.046648979187012, 45.23195266723633, 30.7398...   \n4  [4.067944049835205, 40.6352424621582, 32.47237...   \n\n                                          pitch_mean  \\\n0  [0.4100988507270813, 0.36455661058425903, 0.46...   \n1  [0.37328600883483887, 0.11693736910820007, 0.3...   \n2  [0.49168434739112854, 0.42567530274391174, 0.5...   \n3  [0.38033366203308105, 0.4429582953453064, 0.32...   \n4  [0.4460333585739136, 0.2811882495880127, 0.329...   \n\n                                           pitch_max  \\\n0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.976...   \n2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n\n                                           pitch_min  \\\n0  [0.0020000000949949026, 0.004000000189989805, ...   \n1  [0.003000000026077032, 0.006000000052154064, 0...   \n2  [0.008999999612569809, 0.01600000075995922, 0....   \n3  [0.014000000432133675, 0.02199999988079071, 0....   \n4  [0.004999999888241291, 0.004999999888241291, 0...   \n\n                                           pitch_std  \n0  [0.2942040264606476, 0.3058539032936096, 0.332...  \n1  [0.32932665944099426, 0.1648450493812561, 0.33...  \n2  [0.3070257902145386, 0.21079273521900177, 0.30...  \n3  [0.272826611995697, 0.32914257049560547, 0.260...  \n4  [0.3296523690223694, 0.2335798293352127, 0.289...  \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Define schema log path\nSCHEMA_LOG_PATH = \"/kaggle/working/schema_log.txt\"\n\n# Log the schema to a text file\nwith open(SCHEMA_LOG_PATH, \"w\") as file:\n    file.write(str(spark_df.schema))\n\nprint(f\"Schema logged successfully at {SCHEMA_LOG_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:47:14.689271Z","iopub.execute_input":"2025-05-12T11:47:14.689591Z","iopub.status.idle":"2025-05-12T11:47:14.697234Z","shell.execute_reply.started":"2025-05-12T11:47:14.689569Z","shell.execute_reply":"2025-05-12T11:47:14.695932Z"}},"outputs":[{"name":"stdout","text":"Schema logged successfully at /kaggle/working/schema_log.txt\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Display the first few lines of the schema log\nwith open(SCHEMA_LOG_PATH, \"r\") as file:\n    print(file.read())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:47:17.370189Z","iopub.execute_input":"2025-05-12T11:47:17.370531Z","iopub.status.idle":"2025-05-12T11:47:17.376523Z","shell.execute_reply.started":"2025-05-12T11:47:17.370505Z","shell.execute_reply":"2025-05-12T11:47:17.375495Z"}},"outputs":[{"name":"stdout","text":"StructType([StructField('song_id', StringType(), True), StructField('artist_name', StringType(), True), StructField('title', StringType(), True), StructField('timbre_mean', ArrayType(FloatType(), True), True), StructField('timbre_max', ArrayType(FloatType(), True), True), StructField('timbre_min', ArrayType(FloatType(), True), True), StructField('timbre_std', ArrayType(FloatType(), True), True), StructField('pitch_mean', ArrayType(FloatType(), True), True), StructField('pitch_max', ArrayType(FloatType(), True), True), StructField('pitch_min', ArrayType(FloatType(), True), True), StructField('pitch_std', ArrayType(FloatType(), True), True)])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\n\ndef get_dir_size(path):\n    \"\"\"Calculate the total size of the directory in MB.\"\"\"\n    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            total_size += os.path.getsize(fp)\n    return total_size / (1024 * 1024)  # Convert to MB\n\n# Calculate Parquet and CSV sizes\nparquet_size = get_dir_size(PARTITIONED_OUTPUT_PATH)\ncsv_size = os.path.getsize(CSV_OUTPUT_PATH) / (1024 * 1024)  # Convert to MB\n\nprint(f\"Parquet Size: {parquet_size:.2f} MB\")\nprint(f\"CSV Sample Size: {csv_size:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:47:20.057720Z","iopub.execute_input":"2025-05-12T11:47:20.058609Z","iopub.status.idle":"2025-05-12T11:47:20.340968Z","shell.execute_reply.started":"2025-05-12T11:47:20.058576Z","shell.execute_reply":"2025-05-12T11:47:20.340020Z"}},"outputs":[{"name":"stdout","text":"Parquet Size: 31.85 MB\nCSV Sample Size: 1.75 MB\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import shutil\n\n# Define ZIP output path\nZIP_OUTPUT_PATH = \"/kaggle/working/msd_parquet_by_artist.zip\"\n\n# Path to Parquet directory\nPARQUET_DIR = \"/kaggle/working/msd_agg_parquet_by_artist\"\n\n# Create ZIP\nshutil.make_archive(ZIP_OUTPUT_PATH.replace(\".zip\", \"\"), 'zip', PARQUET_DIR)\n\nprint(f\"Zipping completed. ZIP file created at: {ZIP_OUTPUT_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:48:26.124112Z","iopub.execute_input":"2025-05-12T11:48:26.124391Z","iopub.status.idle":"2025-05-12T11:48:29.711928Z","shell.execute_reply.started":"2025-05-12T11:48:26.124371Z","shell.execute_reply":"2025-05-12T11:48:29.711190Z"}},"outputs":[{"name":"stdout","text":"Zipping completed. ZIP file created at: /kaggle/working/msd_parquet_by_artist.zip\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Drop existing collection\ntry:\n    client = MongoClient(MONGO_URI)\n    db = client[\"msd_database\"]\n    db[\"song_data\"].drop()\n    print(\"Existing MongoDB collection 'song_data' dropped successfully.\")\nexcept Exception as e:\n    print(f\"Error dropping MongoDB collection: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:48:35.993850Z","iopub.execute_input":"2025-05-12T11:48:35.994133Z","iopub.status.idle":"2025-05-12T11:48:36.447947Z","shell.execute_reply.started":"2025-05-12T11:48:35.994112Z","shell.execute_reply":"2025-05-12T11:48:36.447235Z"}},"outputs":[{"name":"stdout","text":"Existing MongoDB collection 'song_data' dropped successfully.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# MongoDB Ingestion - Using Defined Path and Connection\n\nfrom pymongo import MongoClient\n\n# Establish MongoDB Connection\ntry:\n    client = MongoClient(MONGO_URI)\n    db = client[\"msd_database\"]\n    collection = db[\"song_data\"]\n    print(\"MongoDB connection established successfully.\")\nexcept Exception as e:\n    print(f\"MongoDB connection failed: {e}\")\n\n# Function to Convert DataFrame Row to Dictionary\n# Function to convert DataFrame rows to MongoDB-compatible dictionaries\ndef row_to_dict(row):\n    return {\n        \"song_id\": row.song_id,\n        \"artist_name\": row.artist_name,\n        \"title\": row.title,\n        \"timbre_mean\": row.timbre_mean,\n        \"timbre_max\": row.timbre_max,\n        \"timbre_min\": row.timbre_min,\n        \"timbre_std\": row.timbre_std,\n        \"pitch_mean\": row.pitch_mean,\n        \"pitch_max\": row.pitch_max,\n        \"pitch_min\": row.pitch_min,\n        \"pitch_std\": row.pitch_std\n    }\n\n# Re-ingest data to MongoDB\nBATCH_SIZE = 1000\ndata = spark_df.rdd.map(row_to_dict).collect()\n\ntry:\n    for i in range(0, len(data), BATCH_SIZE):\n        batch = data[i:i + BATCH_SIZE]\n        collection.insert_many(batch, ordered=False)\n        print(f\"Inserted batch {i // BATCH_SIZE + 1} of {len(data) // BATCH_SIZE + 1}\")\nexcept Exception as e:\n    print(f\"Error during MongoDB ingestion: {e}\")\n\nprint(\"Data re-ingested to MongoDB successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:48:40.156238Z","iopub.execute_input":"2025-05-12T11:48:40.156534Z","iopub.status.idle":"2025-05-12T11:50:21.773542Z","shell.execute_reply.started":"2025-05-12T11:48:40.156512Z","shell.execute_reply":"2025-05-12T11:50:21.772439Z"}},"outputs":[{"name":"stdout","text":"MongoDB connection established successfully.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Inserted batch 1 of 11\nInserted batch 2 of 11\nInserted batch 3 of 11\nInserted batch 4 of 11\nInserted batch 5 of 11\nInserted batch 6 of 11\nInserted batch 7 of 11\nInserted batch 8 of 11\nInserted batch 9 of 11\nInserted batch 10 of 11\nData re-ingested to MongoDB successfully.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Ensure MongoDB connection is still active\ntry:\n    # Create Unique Index on song_id\n    collection.create_index(\"song_id\", unique=True)\n    print(\"Index created on 'song_id' (Unique).\")\n\n    # Create Index on artist_name\n    collection.create_index(\"artist_name\")\n    print(\"Index created on 'artist_name'.\")\n\n    # Create Index on title\n    collection.create_index(\"title\")\n    print(\"Index created on 'title'.\")\n\nexcept Exception as e:\n    print(f\"Index creation failed: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:50:28.504117Z","iopub.execute_input":"2025-05-12T11:50:28.504389Z","iopub.status.idle":"2025-05-12T11:50:28.861876Z","shell.execute_reply.started":"2025-05-12T11:50:28.504370Z","shell.execute_reply":"2025-05-12T11:50:28.860861Z"}},"outputs":[{"name":"stdout","text":"Index created on 'song_id' (Unique).\nIndex created on 'artist_name'.\nIndex created on 'title'.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}